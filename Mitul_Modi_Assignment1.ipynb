{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TinyImageNetClassification.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1VmBUEItsd22iMcTXxjGpKzPoaEnXlW5X\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InF4ew5U0ZEI"
   },
   "outputs": [],
   "source": [
    "# CSE 666 Assignment 1 : Tiny Imagenet Classification\n",
    "# Name : Mitul Modi\n",
    "# Person No : 50288649\n",
    "# UBIT Name : mitulraj\n",
    "# Contact : mitulraj@buffalo.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FsY3v1Xytzr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import csv\n",
    "import time\n",
    "import PIL\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5G12iu0-ytzy"
   },
   "outputs": [],
   "source": [
    "class TinyImageNetDataset(Dataset):\n",
    "    \"\"\"\n",
    "        Customized Dataset class to load training and validation dataset.\n",
    "        \n",
    "        Code is adapted from code of pytorch sourcecode of DatasetFolder class.\n",
    "        https://pytorch.org/docs/stable/_modules/torchvision/datasets/folder.html#DatasetFolder.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, transform):      \n",
    "\n",
    "        self.transform = transform\n",
    "                        \n",
    "        data_dir = os.path.expanduser(data_dir)\n",
    "        classes = [d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}        \n",
    "        images=[]\n",
    "        labels=[]\n",
    "        \n",
    "        for target in sorted(class_to_idx.keys()):\n",
    "            d = os.path.join(data_dir, target, 'images')\n",
    "            if not os.path.isdir(d):\n",
    "                continue\n",
    "\n",
    "            for root, _, fnames in sorted(os.walk(d)):\n",
    "                for fname in sorted(fnames):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    images.append(path)\n",
    "                    labels.append(class_to_idx[target])\n",
    "\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.images)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        # open image, apply transforms and return with label\n",
    "        image = Image.open(self.images[idx])  # PIL image\n",
    "        image = image.convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]       \n",
    "        return image, label\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "    def get_class_to_idx(self):\n",
    "        return self.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ga5_sxKytz0"
   },
   "outputs": [],
   "source": [
    "class TinyImageNetTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "       Customized Dataset class to load test dataset.\n",
    "       \n",
    "       Code is adapted from code of pytorch sourcecode of DatasetFolder class \n",
    "       https://pytorch.org/docs/stable/_modules/torchvision/datasets/folder.html#DatasetFolder.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, annot_filename, class_to_idx, transform):      \n",
    "\n",
    "        self.transform = transform\n",
    "                        \n",
    "        data_dir = os.path.expanduser(data_dir)\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        with open(os.path.join(data_dir, annot_filename),'r') as f:\n",
    "            reader=csv.reader(f,delimiter='\\t')\n",
    "            for imagename, classname, _, _, _, _ in reader:\n",
    "                images.append(os.path.join(data_dir, 'images', imagename))\n",
    "                labels.append(class_to_idx[classname])\n",
    "                \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "          \n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.images)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        # open image, apply transforms and return with label\n",
    "        image = Image.open(self.images[idx])  # PIL image\n",
    "        image = image.convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oRgzKFQytz2"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\" Convolutional Neural Network implementation \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(3, 32, 3, stride = 1, padding = 1) #(64*64*3) -> (64*64*32)\n",
    "        self.bn0 = nn.BatchNorm2d(32)\n",
    "        self.conv1 = nn.Conv2d(32, 64, 3, stride = 1, padding = 1) #(64*64*32) -> (64*64*64)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, stride = 2, padding = 0) #(64*64*64) -> (31*31*64)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 1, stride = 1, padding = 0) #(31*31*64) -> (31*31*64)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride = 1, padding = 1) #(31*31*64) -> (31*31*64)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, stride = 2, padding = 0) #(31*31*64) -> (15*15*64)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.conv6 = nn.Conv2d(64, 128, 1, stride = 1, padding = 0) #(15*15*64) -> (15*15*128)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.conv7 = nn.Conv2d(128, 256, 3, stride = 2, padding = 0) #(15*15*128) -> (8*8*256)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 512, 3, stride = 2, padding = 0) #(8*8*256) -> (3*3*512)\n",
    "        self.bn8 = nn.BatchNorm2d(512)\n",
    "        self.fc1 = nn.Linear(512*3*3, 512) #(3*3*512 -> 512)\n",
    "        self.bn9 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 200) #(512 -> 200)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "                \n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.bn0(self.dropout(self.conv0(input))))\n",
    "        x = F.relu(self.bn1(self.dropout(self.conv1(x))))\n",
    "        x = F.relu(self.bn2(self.dropout(self.conv2(x))))\n",
    "        x = F.relu(self.bn3(self.dropout(self.conv3(x))))        \n",
    "        x = F.relu(self.bn4(self.dropout(self.conv4(x))))\n",
    "        x = F.relu(self.bn5(self.dropout(self.conv5(x))))\n",
    "        x = F.relu(self.bn6(self.dropout(self.conv6(x))))\n",
    "        x = F.relu(self.bn7(self.dropout(self.conv7(x))))\n",
    "        x = F.relu(self.bn8(self.dropout(self.conv8(x))))\n",
    "        x = x.view(-1, 3*3*512)\n",
    "        x = F.relu(self.bn9(self.dropout(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1hFJwnUmuN4"
   },
   "outputs": [],
   "source": [
    "class ResNetLayer(nn.Module):\n",
    "    \"\"\" Implementaion of One basic Block of Resnet model \"\"\"\n",
    "    def __init__(self, in_feature_maps, out_feature_maps, downsample = True):\n",
    "        super(ResNetLayer, self).__init__()\n",
    "\n",
    "        self.stride = 2 if downsample == True else 1\n",
    "        self.conv0 = nn.Conv2d(in_feature_maps, out_feature_maps, 3, stride = self.stride, padding = 1)\n",
    "        self.bn0 = nn.BatchNorm2d(out_feature_maps)\n",
    "        self.conv1 = nn.Conv2d(out_feature_maps, out_feature_maps, 3, stride = 1, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_feature_maps)\n",
    "\n",
    "        self.skipconn_cnn = nn.Conv2d(in_feature_maps, out_feature_maps, kernel_size=1, stride=self.stride, padding = 0)\n",
    "        self.skipconn_bn = nn.BatchNorm2d(out_feature_maps)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        x = F.relu(self.bn0(self.conv0(input)))\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        skipconn = self.skipconn_bn(self.skipconn_cnn(input))\n",
    "        return F.relu(x + skipconn)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\" Implementaion of ResNet like Neural Network Model \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(3, 64, 3, stride = 1, padding = 1) #(64*64*3) -> (64*64*64)\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = ResNetLayer(64,128, downsample = False) #(64*64*64) -> (64*64*128)\n",
    "        self.layer2 = ResNetLayer(128,128, downsample = True) #(64*64*128) -> (32*32*128)\n",
    "        self.layer3 = ResNetLayer(128,256, downsample = False) #(32*32*128) -> (32*32*256)\n",
    "        self.layer4 = ResNetLayer(256,256, downsample = True) #(32*32*256) -> (16*16*256)\n",
    "        self.layer5 = ResNetLayer(256,512, downsample = False) #(16*16*256) -> (16*16*512)\n",
    "        self.layer6 = ResNetLayer(512,512, downsample = True) #(16*16*512) -> (8*8*512)\n",
    "        self.layer7 = ResNetLayer(512,512, downsample = True) #(8*8*512) -> (4*4*512)\n",
    "        self.layer8 = ResNetLayer(512,512, downsample = True) #(4*4*512) -> (2*2*512)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 200) #(2048 -> 200)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.bn0(self.dropout(self.conv0(input))))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = x.view(-1, 2*2*512)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfjA_5k9gH7U"
   },
   "outputs": [],
   "source": [
    " def init_weights(module):\n",
    "    \"\"\" Function to initialze weights \"\"\"\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        init.xavier_uniform_(module.weight)\n",
    "    if isinstance(module, nn.Linear):\n",
    "        init.xavier_uniform_(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49byTHtbgqsW"
   },
   "outputs": [],
   "source": [
    "def save_model(filename, model, optimizer, scheduler, epoch, loss_tr_hist, loss_val_hist, accuracy_tr_hist, accuracy_val_hist, early_stop_counter):\n",
    "    \"\"\"\n",
    "        Function to save model.\n",
    "        \n",
    "        Function saves model and other training related information so that it can be loaded later to resume training or for inference.\n",
    "        It is called by fit() function to save best model during training.\n",
    "    \"\"\"\n",
    "    state_dict = {\n",
    "        'epoch':epoch,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'loss_tr_hist': loss_tr_hist,\n",
    "        'loss_val_hist': loss_val_hist,\n",
    "        'accuracy_tr_hist': accuracy_tr_hist,\n",
    "        'accuracy_val_hist': accuracy_val_hist,\n",
    "        'early_stop_counter': early_stop_counter\n",
    "    }\n",
    "    torch.save(state_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDq9-b1WpFi2"
   },
   "outputs": [],
   "source": [
    "def load_model(filename, model, optimizer = None, scheduler = None, mode = 'test'):\n",
    "    \"\"\"\n",
    "        This function loads previously saved model and its related training details from file specified by filename.\n",
    "        \n",
    "        Parameters:\n",
    "            filename : path of saved model file.\n",
    "            model : Instance of model to be loaded.\n",
    "            optimizer : Instance of optimizer to be loaded to previous saved state. Useful to resume training of model from saved state.\n",
    "            scheduler : Instance of scheduler to be loaded to previous saved state. Useful to resume training of model from saved state.\n",
    "            mode : Values should be 'train' or 'test'. If value is 'train', it returns model and all other information required to resume training from saved state.\n",
    "                   If value is 'test', it loads and returns only model.\n",
    "    \"\"\"\n",
    "    state_dict = torch.load(filename)\n",
    "\n",
    "    model.load_state_dict(state_dict['model'])\n",
    "    if mode == 'test':\n",
    "        return model\n",
    "\n",
    "    epoch = state_dict['epoch']\n",
    "    optimizer.load_state_dict(state_dict['optimizer'])\n",
    "    loss_tr_hist = state_dict['loss_tr_hist']\n",
    "    loss_val_hist = state_dict['loss_val_hist']\n",
    "    accuracy_tr_hist = state_dict['accuracy_tr_hist']\n",
    "    accuracy_val_hist = state_dict['accuracy_val_hist']\n",
    "    early_stop_counter = state_dict['early_stop_counter']\n",
    "    if scheduler is not None:\n",
    "        scheduler.load_state_dict(state_dict['scheduler'])\n",
    "\n",
    "    return epoch, model, optimizer, scheduler, early_stop_counter, loss_tr_hist, loss_val_hist, accuracy_tr_hist, accuracy_val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8Mk4CuvjYKS"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, criterion):\n",
    "    \"\"\"\n",
    "        Function to perform training step.\n",
    "        \n",
    "        This function performs primary step of training. It performs forward and backward pass to update model parameters. It is called by fit() function during each epoch. \n",
    "        Returns loss and accuracy for current epoch.\n",
    "    \"\"\"\n",
    "    batch = 0\n",
    "    loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    model.train()    \n",
    "    \n",
    "    for X, Y in dataloader:\n",
    "        if gpu:\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "        optimizer.zero_grad()        \n",
    "        logits = model(X)\n",
    "        cur_loss = criterion(logits, Y)\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += cur_loss.item()\n",
    "        pred = logits.argmax(dim = 1)\n",
    "        correct += pred.eq(Y).sum()\n",
    "\n",
    "        # Display Progres Bar. \n",
    "        # Reference - https://stackoverflow.com/questions/46141302/how-to-make-a-still-progress-in-python/46141777\n",
    "        batch += 1\n",
    "        completed = math.floor(batch * dataloader.batch_size / len(dataloader.dataset) * 50)\n",
    "        print('\\r' + 'Training: ' + '▮' * completed + '▯' * (50-completed) + str(completed*2) + '%', end='')\n",
    "    \n",
    "    print('\\r', end='')\n",
    "    \n",
    "    loss = loss / float(len(dataloader.dataset))\n",
    "    accuracy = float(correct) / float(len(dataloader.dataset)) * 100\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNa9j8kxoipQ"
   },
   "outputs": [],
   "source": [
    "def validate(dataloader, model, criterion):\n",
    "    \"\"\"\n",
    "        Function to perform validation step.\n",
    "        \n",
    "        This function is used to perform validation of a model. It is called by function fit() during each epoch.\n",
    "        Returns validation loss and accuracy for current epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    batch = 0    \n",
    "    loss = 0.0\n",
    "    correct = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for X, Y in dataloader:\n",
    "        if gpu:\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "        logits = model(X)\n",
    "        loss += criterion(logits, Y).item()\n",
    "        pred = logits.argmax(dim = 1)\n",
    "        correct += pred.eq(Y).sum()\n",
    "\n",
    "        # Display Progres Bar. \n",
    "        # Reference - https://stackoverflow.com/questions/46141302/how-to-make-a-still-progress-in-python/46141777        \n",
    "        batch += 1\n",
    "        completed = math.floor(batch * dataloader.batch_size / len(dataloader.dataset) * 50)\n",
    "        print('\\r' + 'Validation: ' + '▮' * completed + '▯' * (50-completed) + str(completed*2) + '%', end='')\n",
    "    \n",
    "    print('\\r', end='')        \n",
    "        \n",
    "    loss = loss / float(len(dataloader.dataset))\n",
    "    accuracy = float(correct) / float(len(dataloader.dataset)) * 100\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2anfPLDHiE1X"
   },
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    \"\"\" Infers output of given trained model for given test data. \"\"\"\n",
    "    loss = 0.0\n",
    "    correct = 0.0\n",
    "    accuracy = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for X, Y in dataloader:\n",
    "        if gpu:\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()        \n",
    "        logits = model(X)\n",
    "        loss += criterion(logits, Y).item()\n",
    "        pred = logits.argmax(dim = 1)\n",
    "        correct += pred.eq(Y).sum()\n",
    "        \n",
    "    loss = loss / float(len(dataloader_test.dataset))\n",
    "    accuracy = float(correct) / float(len(dataloader_test.dataset)) * 100\n",
    "    return pred, loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRQCEl-Gyt0F"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fit(dataloader_tr, dataloader_val, model, criterion, optimizer, max_epoch = 100, scheduler = None, filename = None, early_stop = True, patience = 10, resume = False):\n",
    "    \"\"\"\n",
    "        Function to train and validate model for given epochs. It calls train and validate functions.\n",
    "        \n",
    "        Parameters: \n",
    "            dataloader_tr : data loader for training dataset.\n",
    "            dataloader_val : dataloader for validation dataset.\n",
    "            model : Instance of a Model. which is to be trained.\n",
    "            criterion : criterion or loss function\n",
    "            optimizer : Instance of Optimizer.\n",
    "            max_epoch : Maximum number of epochs to train model\n",
    "            scheduler : learning rate scheduler to change value of learning rate while model is trained.\n",
    "            filename : Filename to save the best model during training. Function will save model with lowest validation loss, so that best model can be retrieved after training.\n",
    "                       If resume = True, filename will be used to load previously saved model and resume the training.\n",
    "            early_stop : If True, training will be stopped when validation_loss doesnt improve for epochs specified by patience. Recommended to prevent overfitting.\n",
    "            patience : number of epochs to wait for early_stopping.\n",
    "            resume : If True, model specified by filename will be loaded and training will be resumed for loaded model.\n",
    "        Returns history of Training and Validation loss, and Training and Validation Accuracy.\n",
    "    \"\"\"\n",
    "    start_epoch = 0\n",
    "    early_stop_counter = 0\n",
    "    min_loss_val = 1e10    \n",
    "    loss_tr_hist = []\n",
    "    loss_val_hist = []\n",
    "    accuracy_tr_hist = []\n",
    "    accuracy_val_hist = []\n",
    "\n",
    "    if resume == True:\n",
    "        if filename is None:\n",
    "            print('Please Provide File Name to load model')\n",
    "            return\n",
    "        start_epoch, model, optimizer, scheduler, early_stop_counter, loss_tr_hist, loss_val_hist, accuracy_tr_hist, accuracy_val_hist = load_model(filename, model, optimizer, scheduler, mode = 'train')\n",
    "        \n",
    "        \n",
    "    for epoch in range(start_epoch+1, max_epoch + 1):\n",
    "        t0 = time.time()\n",
    "\n",
    "        loss_tr, accuracy_tr = train(dataloader_tr, model, optimizer, criterion)\n",
    "        loss_tr_hist.append(loss_tr)\n",
    "        accuracy_tr_hist.append(accuracy_tr)\n",
    "\n",
    "        loss_val, accuracy_val = validate(dataloader_val, model, criterion)\n",
    "        loss_val_hist.append(loss_val)\n",
    "        accuracy_val_hist.append(accuracy_val)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss_val)\n",
    "\n",
    "        early_stop_counter += 1\n",
    "        if loss_val < min_loss_val:\n",
    "            if filename is not None:                \n",
    "                save_model(filename, model, optimizer, scheduler, epoch, loss_tr_hist, loss_val_hist, accuracy_tr_hist, accuracy_val_hist, early_stop_counter)\n",
    "            min_loss_val = loss_val\n",
    "            early_stop_counter = 0\n",
    "        \n",
    "        print(\"[{0:3d} / {1:3d}]  |  Loss_Tr: {2:7.4f}  |  Loss_Val: {3:7.4f}  |  Acc_Tr: {4:7.4f}  |  Acc_Val: {5:7.4f}  |  Time taken: {6:7.4f}s  |  {7}\".format(epoch, max_epoch, loss_tr, loss_val, accuracy_tr, accuracy_val, time.time() - t0, \"Best Model\" if early_stop_counter == 0 else \"\"))\n",
    "        \n",
    "        if early_stop == True and early_stop_counter > patience:\n",
    "            print('\\nEarly Stopping ... !')\n",
    "            break\n",
    "    return loss_tr_hist, loss_val_hist, accuracy_tr_hist, accuracy_val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "De9DbWW4fchm"
   },
   "outputs": [],
   "source": [
    "def plot(loss_tr_hist, loss_val_hist, accuracy_tr_hist, accuracy_val_hist):\n",
    "    \"\"\" Plots training loss vs validation loss and training accuracy vs validation accuracy graphs. \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(10)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(loss_tr_hist)\n",
    "    plt.plot(loss_val_hist)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(('Training', 'Validation'))\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(accuracy_tr_hist)\n",
    "    plt.plot(accuracy_val_hist)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(('Training', 'Validation'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "frL-Doxuytzu",
    "outputId": "67d1e6e9-dd7e-4e83-9c32-c2f04a4dbb8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset related parameters\n",
    "\n",
    "data_dir = 'tiny-imagenet-200'\n",
    "\n",
    "transform1 = transforms.RandomApply([\n",
    "    transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20, resample=PIL.Image.BICUBIC),\n",
    "    transforms.RandomAffine(degrees = 0, translate=(0.1,0.25), scale=(1,1.5), shear=5, resample=PIL.Image.BICUBIC, fillcolor=0)\n",
    "])\n",
    "transform2 = transforms.ToTensor()\n",
    "\n",
    "workers = 1\n",
    "batch_size = 64\n",
    "\n",
    "# Check if GPU is available\n",
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "if gpu:\n",
    "    print('Training on GPU')\n",
    "else:\n",
    "    print('Training on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "r__38Go0ytz5",
    "outputId": "9caeadcc-a81d-44e9-c3d0-d8b3db162602"
   },
   "outputs": [],
   "source": [
    "# Load training dataset and split into training and validation sets by stratified shuffle split so that each class has equal training and validation samples.\n",
    "\n",
    "dataset = TinyImageNetDataset(data_dir+'/train', transform=transforms.Compose([transform1, transform2]))\n",
    "labels = dataset.get_labels()\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "idx_tr, idx_val = next(sss.split(labels, labels))\n",
    "\n",
    "dataset_tr = torch.utils.data.Subset(dataset, idx_tr)\n",
    "dataset_val = torch.utils.data.Subset(dataset, idx_val)\n",
    "\n",
    "dataloader_tr = torch.utils.data.DataLoader(dataset_tr, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "print('Training Dataset Length: ' + str(len(dataset_tr)))\n",
    "print('Validation Dataset Length: ' + str(len(dataset_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pSExNUn-ytz7",
    "outputId": "b5a82b32-9338-4907-8324-cfa573a58874"
   },
   "outputs": [],
   "source": [
    "# Load test dataset.\n",
    "\n",
    "class_to_idx = dataset.get_class_to_idx()\n",
    "dataset_test = TinyImageNetTestDataset(data_dir+'/val', annot_filename = 'val_annotations.txt', class_to_idx = class_to_idx, transform=transform2)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "print('Test Dataset Length: ' + str(len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSrSnIL50LkT"
   },
   "outputs": [],
   "source": [
    "# Initialize model and its weights\n",
    "#model = ResNet()\n",
    "model = CNN()\n",
    "model.apply(init_weights)\n",
    "if gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxEE_ntuKE6c"
   },
   "outputs": [],
   "source": [
    "# Initialize hyper parameters and functions required for training\n",
    "max_epochs = 100\n",
    "lr = 0.015 #0.015 with weight decay 0.05 for ResNet without Weight Decay\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, dampening=0, weight_decay=0.001, nesterov=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=7, verbose=False, threshold=0.0005, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_filename = 'best_model_cnn_47.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "GNw_RAR49pIH",
    "outputId": "a65a2751-4801-4915-ac1b-39c96c26ee26"
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "loss_tr_hist, loss_val_hist, accuracy_tr_hist, accuracy_val_hist = fit(dataloader_tr, dataloader_val, model, criterion, optimizer, scheduler = scheduler, filename = model_filename, resume = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "HNSmo-NMfmc1",
    "outputId": "03639eab-1667-4bbf-b221-30e9c72eedbd"
   },
   "outputs": [],
   "source": [
    "plot(loss_tr_hist, loss_val_hist, accuracy_tr_hist, accuracy_val_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PvGQw6ZWmfhy",
    "outputId": "b93344b7-290f-4c28-9a5e-23c31c14cf34"
   },
   "outputs": [],
   "source": [
    "#model = ResNet()\n",
    "model = CNN()\n",
    "model = load_model(model_filename, model, mode = 'test')\n",
    "if gpu:\n",
    "    model.cuda()\n",
    "pred, loss_test, accuracy_test = test(model, dataloader_test)\n",
    "print('Test Loss: {0:7.4f}  |  Test Accuracy: {1:7.4f}'.format(loss_test, accuracy_test))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TinyImageNetClassification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
